{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# PART 1\n",
    "## Webscraping Toronto's Wikipedia page\n",
    "In this section, we download the content of the Wikipedia page about Toronto neighborhoods and postal codes ([link])(https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M) to populate a DataFrame"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports used in this stage\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "source": [
    "Using `requests.get()` to get the contents of the page, and parsing it with BeautifulSoup. We also print the page title to check if we have accessed the correct page:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tor_url = 'https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M'\n",
    "htmldata = requests.get(url=tor_url).text\n",
    "soup = BeautifulSoup(htmldata, 'lxml')\n",
    "print(soup.title)"
   ]
  },
  {
   "source": [
    "We count the number of tables, and print the beginning of each table to see which of them is the one that we want:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tables = soup.find_all('table')\n",
    "print('There are {:} tables in the document.'.format(len(tables)))\n",
    "# printing the beginning of each table to see which one is the right one\n",
    "_ = [print(tables[i].prettify()[:250]) for i in range(len(tables))]"
   ]
  },
  {
   "source": [
    "From the sample, we can see that the correct table is found in `tables[0]`.\n",
    "\n",
    "Once the table is identified, we parse its contents, while also getting rid of undesired data:\n",
    "- Postal codes that were not assigned yet\n",
    "- Extraneous characters such as **`( ) /`** and extra whitespaces"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "neigh_tbl = tables[0]\n",
    "neigh_lst = []\n",
    "for val in (neigh_tbl.find_all('td'))[:-1]:\n",
    "    strtmp = val.get_text(strip=True, separator=';')\n",
    "    strlist = strtmp.replace('/', ',').split(';')\n",
    "    # restrict the parsing only to the postal codes already assigned, otherwise skip\n",
    "    if strlist[1] != 'Not assigned':\n",
    "        post = strlist[0]\n",
    "        bor = strlist[1]\n",
    "        # merge contents of the other cells (neighborhoods)\n",
    "        nei = ' '.join(strlist[2:])\n",
    "        # parsing to remove extraneous symbols\n",
    "        nei = nei.replace('( ', '').replace('(', '').replace(' ,', ',').replace(')', '')\n",
    "        # removing spaces at the beginning and the end of the string\n",
    "        nei = nei.lstrip().rstrip()\n",
    "        strtmp = [post, bor, nei]\n",
    "        neigh_lst.append(strtmp)"
   ]
  },
  {
   "source": [
    "Once the list is correctly parsed, we convert it to a pandas DataFrame:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the resulting list to a pandas DataFrame\n",
    "df = pd.DataFrame(neigh_lst, columns=['Postal code', 'Borough', 'Neighborhoods'])\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "Checking DataFrame size"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "source": [
    "# PART 2\n",
    "## Getting Latitude and Longitude of the Postal Codes\n",
    "\n",
    "We obtained the Latitude and Longitude values from ArcGIS using `geocoder`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "!pip install geocoder\n",
    "import geocoder\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm  # Color palettes\n",
    "from sklearn.cluster import KMeans  # ML library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open previously saved DataFrame, or create a new one and save a local copy\n",
    "fname = 'Toronto Neighborhoods.csv'\n",
    "\n",
    "if os.path.exists(fname):\n",
    "     print(\"File '{}' already exists. Loading from cache...\".format(fname))\n",
    "     df = pd.read_csv(fname, index_col=0)\n",
    "else:\n",
    "     #create a copy of the DataFrame using Postal Code as index\n",
    "     df2 = df.set_index('Postal code')\n",
    "     df2['Latitude'], df2['Longitude'] = 0, 0\n",
    "\n",
    "     # add latitude and longitude using geocoder\n",
    "     for p in df2.index:\n",
    "          # reply = None\n",
    "          # while (reply is None):\n",
    "          reply = geocoder.arcgis('{} Toronto ON, Canada'.format(p))\n",
    "          print(reply, reply.latlng)\n",
    "          df2.loc[p, ['Latitude', 'Longitude']] = reply.latlng\n",
    "\n",
    "     print(\"There are {} missing coordinates after the query\".format(sum([df2['Latitude'].isna().sum(),\n",
    "          df2['Longitude'].isna().sum()])))\n",
    "     # restore numerical index and Postal Code column\n",
    "     df = df2.reset_index()\n",
    "     # save results to a file\n",
    "     df.to_csv(fname)\n",
    "     print(\"DataFrame saved as '{}'.\".format(fname))\n"
   ]
  },
  {
   "source": [
    "Checking borough names and shape of the resulting DataFrame"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.Borough.unique())\n",
    "df.shape"
   ]
  },
  {
   "source": [
    " # PART 3\n",
    "## Clustering the neighborhoods using data from the Foursquare API\n",
    "We kept the same parameters from the Manhattan sample exercise, and reused the function ```getNearbyVenues``` from it"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#foursquare credentials\n",
    "CLIENT_ID = 'L2LRCN30Z5RRWFLVVZVWHPL1JTUF05IZ3IAMMRZX40MU0TIF' # your Foursquare ID\n",
    "CLIENT_SECRET = '01SEKO1V4WEHUQSEX0QJJ0FVKCIWBOEWFXXWU4OBUWLW5WQU' # your Foursquare Secret\n",
    "VERSION = '20180605' # Foursquare API version\n",
    "LIMIT = 100 # A default Foursquare API limit value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get nearby venues and export to a DataFrame\n",
    "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        print(name)\n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET, VERSION, lat, lng, radius, LIMIT)\n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append(\n",
    "            [(name, lat, lng, v['venue']['name'], v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'], v['venue']['categories'][0]['name'])\n",
    "            for v in results]\n",
    "            )\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Neighborhoods', 'Neighborhood Latitude', 'Neighborhood Longitude',\n",
    "                             'Venue', 'Venue Latitude', 'Venue Longitude', 'Venue Category']\n",
    "\n",
    "    return(nearby_venues)"
   ]
  },
  {
   "source": [
    "To save time and queries from the Foursquare API, we save the previous results in a file. In case the file is detected, it is loaded from disk instead of executing the query."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'Toronto Venues.csv'\n",
    "if os.path.exists(fname):\n",
    "    print('File \"{}\" exists, loading from cache'.format(fname))\n",
    "    venues = pd.read_csv(fname, index_col=0)\n",
    "else:\n",
    "    venues = getNearbyVenues(df.Neighborhoods, df.Latitude, df.Longitude)\n",
    "    venues.to_csv(fname)\n",
    "\n",
    "print('Dataframe shape:', venues.shape)"
   ]
  },
  {
   "source": [
    "Some of the venues from FSQ are actually neighborhood names, dropping...."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venues = venues[~(venues['Venue Category'] == 'Neighborhood') ]\n",
    "venues.shape"
   ]
  },
  {
   "source": [
    "There are several similar categories (for example, **Café** vs **Coffee Shop**, **History Museum** vs **Museum**). We have tried to reduce the number of categories a bit. This was not exaustive, we just adjusted the obvious redundancies. Some other categories could probably be dropped altogether (**Intersection** and **Bridge** for example)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} unique categories.'.format(len(venues['Venue Category'].unique())))\n",
    "\n",
    "replacements = [['Café', 'Coffee Shop'], ['History Museum', 'Museum'], ['Golf Driving Range', 'Golf Course'],\n",
    "                ['Gym', 'Gym & Fitness Center'], ['Gym / Fitness Center', 'Gym & Fitness Center'], ['Gym Pool', 'Pool'],\n",
    "                ['Taiwanese Restaurant', 'Thai Restaurant'], ['Art Gallery', 'Art Gallery / Art Museum'], \n",
    "                ['Art Museum', 'Art Gallery / Art Museum'], ['Opera House', 'Concert Hall'], ['Jazz Club', 'Music Venue'],\n",
    "                ['Korean BBQ Restaurant', 'Korean Restaurant'], ['Basketball Stadium', 'Stadium'], ['College Stadium','Stadium'],\n",
    "                ['Bus Line', 'Public Transp. (bus/rail/metro)'], ['Bus Station', 'Public Transp. (bus/rail/metro)'],\n",
    "                ['Metro Station', 'Public Transp. (bus/rail/metro)'], ['Light Rail Station', 'Public Transp. (bus/rail/metro)'],\n",
    "                ['Bar', 'Pubs and Bars'], ['Beer Bar', 'Pubs and Bars'], ['Cocktail Bar', 'Pubs and Bars'],\n",
    "                ['Gastropub', 'Pubs and Bars'], ['Hotel Bar', 'Pubs and Bars'], ['Irish Pub', 'Pubs and Bars'],\n",
    "                ['Pub', 'Pubs and Bars'], ['Sake Bar', 'Pubs and Bars'], ['Sports Bar', 'Pubs and Bars'],\n",
    "                ['Wine Bar', 'Pubs and Bars'], ['Food Court', 'Street Food'], ['Food Truck', 'Street Food'],\n",
    "                ['Garden', 'Gardens'], ['Sculpture Garden', 'Gardens'], ['Sushi Restaurant', 'Japanese Restaurant']]\n",
    "\n",
    "for r in replacements:\n",
    "    venues.loc[venues['Venue Category'] == r[0], 'Venue Category'] = r[1]\n",
    "print('Number of unique categories after grouping: {}'.format(len(venues['Venue Category'].unique())))\n",
    "\n",
    "# for r in venues['Venue Category'].unique():\n",
    "#     if 'restaurant' in r.lower():\n",
    "#         print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractors = pd.DataFrame(columns=venues.columns)\n",
    "restaurants = contractors.copy()\n",
    "contractor_categories = ['Construction & Landscaping', 'Business Service', 'Home Service']\n",
    "for idx in range(len(venues)):\n",
    "    if (venues.iloc[idx]['Venue Category']) in contractor_categories:\n",
    "        contractors = contractors.append(venues.iloc[idx])\n",
    "    elif 'restaurant' in (venues.iloc[idx]['Venue Category']).lower():\n",
    "        restaurants = restaurants.append(venues.iloc[idx])\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the neighborhood by restaurant counts\n",
    "restaurant_counts = restaurants.groupby('Neighborhoods')['Venue Category'].count()\n",
    "restaurant_counts.columns = ['count']\n",
    "\n",
    "# group the restaurants by type\n",
    "onehot = pd.get_dummies(restaurants[['Venue Category']], prefix='', prefix_sep='')\n",
    "rest_onehot = pd.concat([restaurants[['Neighborhoods']], onehot], axis=1)\n",
    "rest_onehot = rest_onehot.groupby('Neighborhoods').sum().reset_index()\n",
    "rest_onehot.shape\n",
    "rest_onehot.set_index('Neighborhoods', inplace=True)\n",
    "\n",
    "print(rest_onehot.shape)\n",
    "cols = rest_onehot.columns.values\n",
    "for i in range(len(cols)):\n",
    "    if cols[i] == 'Restaurant':\n",
    "        cols[i] = 'Unspecified Restaurant'\n",
    "cols = [(' '.join(c.split(' ')[:-1])).rstrip() for c in rest_onehot.columns]\n",
    "rest_onehot.columns = cols\n",
    "rest_onehot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} different restaurant categories in Toronto'.format(len(rest_onehot.columns)))\n",
    "top_restaurant_counts = rest_onehot.sum()\n",
    "top_restaurant_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_counts_neigh = rest_onehot[rest_onehot.columns[:-2]].sum(1)\n",
    "top_counts_neigh.head()"
   ]
  },
  {
   "source": [
    "Create a list with the top 10 most common restaurants in a neighborhood (if there are that many categories)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = rest_onehot.iloc[i].sort_values()[::-1]\n",
    "a.values"
   ]
  },
  {
   "source": [
    "Ranking and counts of each type of restaurant in the neighborhoods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10list = []\n",
    "for i in range(len(rest_onehot)):\n",
    "    t10l = rest_onehot.iloc[i].sort_values()[::-1]\n",
    "    t10l = (['{} ({})'.format(t10l[t10l > 0].index[i], t10l.values[i]) for i in range(len(t10l[t10l > 0]))] + 10*[''])[:10]\n",
    "    top10list.append(t10l)\n",
    "\n",
    "top10list = pd.DataFrame(top10list, index=rest_onehot.index, columns=range(1, 11))\n",
    "top10list.head()"
   ]
  },
  {
   "source": [
    "## Clustering the neighborhoods by similarity\n",
    "\n",
    "Now we use *K-means* to find similar neighborhoods in Toronto city."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import folium  # Plotting maps with overlays\n",
    "import branca   # Fancy HTML text inside bubbles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 4\n",
    "cl = KMeans(init='k-means++', n_clusters = n_clusters, random_state=188, n_init=100)\n",
    "counts_neigh = np.array([top_counts_neigh.values, top_counts_neigh.values]).T\n",
    "cl.fit(counts_neigh)\n",
    "print(cl.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an labeled index for the classes\n",
    "class_names = ['Low', 'Medium', 'High', 'Very High']\n",
    "class_counts = np.zeros((n_clusters, 3)).astype('object')\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    class_counts[i, :] = [i, top_counts_neigh[cl.labels_ == i].max(), top_counts_neigh[cl.labels_ == i].min()]\n",
    "\n",
    "class_labels = np.zeros_like(cl.labels_).astype('object')\n",
    "reverse_index = class_counts[:, 1].argsort().argsort()\n",
    "\n",
    "for pos, i in enumerate(class_counts[:, 1].argsort().argsort()):\n",
    "    class_counts[pos, 0] = class_names[i]\n",
    "\n",
    "for i in range(len(class_labels)):\n",
    "    class_labels[i] = '{} ({})'.format(class_names[reverse_index[cl.labels_[i]]], top_counts_neigh[i])\n"
   ]
  },
  {
   "source": [
    "Restore the latitude and longitude values\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore latitude and longitude data\n",
    "top10list['Latitude'], top10list['Longitude'] = 0, 0\n",
    "for n in top10list.index:\n",
    "    top10list.loc[n, 'Latitude'] = df[df['Neighborhoods'] == n]['Latitude'].values\n",
    "    top10list.loc[n, 'Longitude'] = df[df['Neighborhoods'] == n]['Longitude'].values\n",
    "top10list.head()"
   ]
  },
  {
   "source": [
    "Here we plot the neighborhood's markers grouped by color. The colors represent the number of restaurants in each neighborhoods."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = cm.nipy_spectral(np.linspace(0, 1, n_clusters))\n",
    "\n",
    "reply = geocoder.arcgis('Toronto, ON, Canada')\n",
    "reply.latlng\n",
    "# we added a small correction in latlng to allow for greater zoom\n",
    "map_toronto = folium.Map(location=list(reply.latlng + np.array([.075, 0])), zoom_start=11)\n",
    "\n",
    "# add markers to map\n",
    "for lat, lng, label, grplbl, cidx, top in zip(top10list['Latitude'], top10list['Longitude'], top10list.index.values, class_labels, cl.labels_, top10list[top10list.columns[:10]].values):\n",
    "    cv = (255*colors[cidx]).astype('int')\n",
    "    chex = '#{:02x}{:02x}{:02x}'.format(cv[0], cv[1], cv[2])\n",
    "    #l = ('<b>Group {:}:</b><br><i>{:}:</i><br>{:}, {:}, {:}, {:}, {:}, {:}, {:}, {:}, {:}, {:}').format(cidx, label, top[0], top[1], top[2], top[3], top[4], top[5], top[6], top[7], top[8], top[9])\n",
    "    l = ('<b>{:}:</b><br><i>{:}:</i><br>{:}, {:}, {:}, {:}, {:}, {:}, {:}, {:}, {:}, {:}').format(grplbl, label, top[0], top[1], top[2], top[3], top[4], top[5], top[6], top[7], top[8], top[9])\n",
    "    # print(l)\n",
    "    lbl = branca.element.IFrame(l, width=250, height=130)\n",
    "    label = folium.Popup(lbl)#, parse_html=True)\n",
    "    folium.CircleMarker([lat, lng], radius=6, popup=label, color='black', weight=1, fill=True, fill_color=chex, fill_opacity=1,\n",
    "    parse_html=True).add_to(map_toronto)\n",
    "map_toronto"
   ]
  },
  {
   "source": [
    "It is possible to see tha the more central regions (Downtown Toronto) have the biggest concentration of restaurants. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10list[[('Very High' in c) for c in class_labels]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(geocoder.arcgis('M4L, Toronto, ON, Canada').latlng)\n",
    "print(geocoder.arcgis('M5E, Toronto, ON, Canada').latlng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply.latlng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}